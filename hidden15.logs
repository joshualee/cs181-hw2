* * * * * * * * *
Parameters => Epochs: 200, Learning Rate: 0.100000
Type of network used: HiddenNetwork
Input Nodes: 196, Hidden Nodes: 15, Output Nodes: 10
* * * * * * * * *
1 Performance: 0.21244444 0.194
2 Performance: 0.68111111 0.638
3 Performance: 0.83177778 0.820
4 Performance: 0.87344444 0.852
5 Performance: 0.88800000 0.863
6 Performance: 0.89544444 0.864
7 Performance: 0.90044444 0.867
8 Performance: 0.90366667 0.878
9 Performance: 0.90666667 0.880
10 Performance: 0.90900000 0.884
11 Performance: 0.91077778 0.885
12 Performance: 0.91244444 0.886
13 Performance: 0.91400000 0.886
14 Performance: 0.91600000 0.886
15 Performance: 0.91822222 0.887
16 Performance: 0.92044444 0.888
17 Performance: 0.92133333 0.888
18 Performance: 0.92244444 0.895
19 Performance: 0.92322222 0.895
20 Performance: 0.92422222 0.897
21 Performance: 0.92511111 0.897
22 Performance: 0.92600000 0.900
23 Performance: 0.92700000 0.903
24 Performance: 0.92744444 0.903
25 Performance: 0.92811111 0.905
26 Performance: 0.92911111 0.905
27 Performance: 0.92955556 0.905
28 Performance: 0.93066667 0.904
29 Performance: 0.93133333 0.902
30 Performance: 0.93244444 0.901
31 Performance: 0.93266667 0.902
32 Performance: 0.93344444 0.904
33 Performance: 0.93355556 0.904
34 Performance: 0.93444444 0.903
35 Performance: 0.93533333 0.904
logs
[(0.21244444444444444, 0.194), (0.6811111111111111, 0.638), (0.8317777777777777, 0.82), (0.8734444444444445, 0.852), (0.888, 0.863), (0.8954444444444445, 0.864), (0.9004444444444445, 0.867), (0.9036666666666666, 0.878), (0.9066666666666666, 0.88), (0.909, 0.884), (0.9107777777777778, 0.885), (0.9124444444444444, 0.886), (0.914, 0.886), (0.916, 0.886), (0.9182222222222223, 0.887), (0.9204444444444444, 0.888), (0.9213333333333333, 0.888), (0.9224444444444444, 0.895), (0.9232222222222223, 0.895), (0.9242222222222222, 0.897), (0.9251111111111111, 0.897), (0.926, 0.9), (0.927, 0.903), (0.9274444444444444, 0.903), (0.9281111111111111, 0.905), (0.9291111111111111, 0.905), (0.9295555555555556, 0.905), (0.9306666666666666, 0.904), (0.9313333333333333, 0.902), (0.9324444444444444, 0.901), (0.9326666666666666, 0.902), (0.9334444444444444, 0.904), (0.9335555555555556, 0.904), (0.9344444444444444, 0.903), (0.9353333333333333, 0.904)]
[0.21244444444444444, 0.6811111111111111, 0.8317777777777777, 0.8734444444444445, 0.888, 0.8954444444444445, 0.9004444444444445, 0.9036666666666666, 0.9066666666666666, 0.909, 0.9107777777777778, 0.9124444444444444, 0.914, 0.916, 0.9182222222222223, 0.9204444444444444, 0.9213333333333333, 0.9224444444444444, 0.9232222222222223, 0.9242222222222222, 0.9251111111111111, 0.926, 0.927, 0.9274444444444444, 0.9281111111111111, 0.9291111111111111, 0.9295555555555556, 0.9306666666666666, 0.9313333333333333, 0.9324444444444444, 0.9326666666666666, 0.9334444444444444, 0.9335555555555556, 0.9344444444444444, 0.9353333333333333]
[0.194, 0.638, 0.82, 0.852, 0.863, 0.864, 0.867, 0.878, 0.88, 0.884, 0.885, 0.886, 0.886, 0.886, 0.887, 0.888, 0.888, 0.895, 0.895, 0.897, 0.897, 0.9, 0.903, 0.903, 0.905, 0.905, 0.905, 0.904, 0.902, 0.901, 0.902, 0.904, 0.904, 0.903, 0.904]
